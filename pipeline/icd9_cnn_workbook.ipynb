{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note:\n",
    "this is a workbook notebook for testing the cnn model... the final notebook will have much more examples and will have visualization on how the data looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "import random\n",
    "\n",
    "\n",
    "#keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, MaxPooling1D, Convolution1D, Embedding\n",
    "from keras.layers.merge import Concatenate\n",
    "\n",
    "# Custom functions\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import database_selection\n",
    "import vectorization\n",
    "import helpers\n",
    "import icd9_cnn_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reading file\n",
    "full_df = pd.read_csv('../data/disch_notes_all_icd9.csv',\n",
    "                 names = ['HADM_ID', 'SUBJECT_ID', 'DATE', 'ICD9','TEXT'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52696, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5270, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>ICD9</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109180</td>\n",
       "      <td>25962</td>\n",
       "      <td>2107-01-02 00:00:00</td>\n",
       "      <td>42731 0389 4280 51881 78820 5939 7140</td>\n",
       "      <td>Admission Date:  [**2107-1-1**]     Discharge ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189225</td>\n",
       "      <td>23722</td>\n",
       "      <td>2108-03-04 00:00:00</td>\n",
       "      <td>7700 76519 76528 7706</td>\n",
       "      <td>Admission Date: [**2108-2-26**]        Dischar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>129143</td>\n",
       "      <td>3703</td>\n",
       "      <td>2173-08-21 00:00:00</td>\n",
       "      <td>51881 42833 5849 2762 32723 4280 25000 4412 40...</td>\n",
       "      <td>Admission Date:  [**2173-8-16**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>187236</td>\n",
       "      <td>29315</td>\n",
       "      <td>2174-05-11 00:00:00</td>\n",
       "      <td>7213 2910 9974 5601 73730 4019 5711 30391 30001</td>\n",
       "      <td>Admission Date:  [**2174-5-3**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134128</td>\n",
       "      <td>28140</td>\n",
       "      <td>2105-06-03 00:00:00</td>\n",
       "      <td>43411 5849 5750 5601 78959 5762 1570 42822 401...</td>\n",
       "      <td>Admission Date:  [**2105-5-30**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>146974</td>\n",
       "      <td>79915</td>\n",
       "      <td>2169-01-26 00:00:00</td>\n",
       "      <td>570 99594 5724 5722 3485 5770 5845 56723 51881...</td>\n",
       "      <td>Admission Date:  [**2168-12-25**]             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>132278</td>\n",
       "      <td>3792</td>\n",
       "      <td>2206-10-20 00:00:00</td>\n",
       "      <td>4239 42820 4254 4160 4233 4280 42731 78551 427...</td>\n",
       "      <td>Admission Date:  [**2206-10-20**]             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>185036</td>\n",
       "      <td>43926</td>\n",
       "      <td>2197-05-24 00:00:00</td>\n",
       "      <td>4240 3970 51851 99801 4271 9971 42822 4254 511...</td>\n",
       "      <td>Admission Date:  [**2197-5-11**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>113161</td>\n",
       "      <td>13984</td>\n",
       "      <td>2138-08-15 00:00:00</td>\n",
       "      <td>85140 80100 80220 30560 30540 8748 8730 30520</td>\n",
       "      <td>Admission Date:  [**2138-7-30**]       Dischar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>167539</td>\n",
       "      <td>81407</td>\n",
       "      <td>2141-03-10 00:00:00</td>\n",
       "      <td>4412 2866 2851 99811 51881 9971 4275 5119 4233...</td>\n",
       "      <td>Admission Date:  [**2141-2-22**]              ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HADM_ID  SUBJECT_ID                 DATE  \\\n",
       "0   109180       25962  2107-01-02 00:00:00   \n",
       "1   189225       23722  2108-03-04 00:00:00   \n",
       "2   129143        3703  2173-08-21 00:00:00   \n",
       "3   187236       29315  2174-05-11 00:00:00   \n",
       "4   134128       28140  2105-06-03 00:00:00   \n",
       "5   146974       79915  2169-01-26 00:00:00   \n",
       "6   132278        3792  2206-10-20 00:00:00   \n",
       "7   185036       43926  2197-05-24 00:00:00   \n",
       "8   113161       13984  2138-08-15 00:00:00   \n",
       "9   167539       81407  2141-03-10 00:00:00   \n",
       "\n",
       "                                                ICD9  \\\n",
       "0              42731 0389 4280 51881 78820 5939 7140   \n",
       "1                              7700 76519 76528 7706   \n",
       "2  51881 42833 5849 2762 32723 4280 25000 4412 40...   \n",
       "3    7213 2910 9974 5601 73730 4019 5711 30391 30001   \n",
       "4  43411 5849 5750 5601 78959 5762 1570 42822 401...   \n",
       "5  570 99594 5724 5722 3485 5770 5845 56723 51881...   \n",
       "6  4239 42820 4254 4160 4233 4280 42731 78551 427...   \n",
       "7  4240 3970 51851 99801 4271 9971 42822 4254 511...   \n",
       "8      85140 80100 80220 30560 30540 8748 8730 30520   \n",
       "9  4412 2866 2851 99811 51881 9971 4275 5119 4233...   \n",
       "\n",
       "                                                TEXT  \n",
       "0  Admission Date:  [**2107-1-1**]     Discharge ...  \n",
       "1  Admission Date: [**2108-2-26**]        Dischar...  \n",
       "2  Admission Date:  [**2173-8-16**]              ...  \n",
       "3  Admission Date:  [**2174-5-3**]              D...  \n",
       "4  Admission Date:  [**2105-5-30**]              ...  \n",
       "5  Admission Date:  [**2168-12-25**]             ...  \n",
       "6  Admission Date:  [**2206-10-20**]             ...  \n",
       "7  Admission Date:  [**2197-5-11**]              ...  \n",
       "8  Admission Date:  [**2138-7-30**]       Dischar...  \n",
       "9  Admission Date:  [**2141-2-22**]              ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking just a subset of the records for developing models\n",
    "df = full_df.sample(frac=0.1).reset_index(drop=True)\n",
    "print df.shape\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre processing ICD 9 codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# instead of finding out the top 20 leave icd-9 codes and filter records based on that\n",
    "# we will use all records and replace the leave icd-9 codes with its grandparents code in the first level of the hierarchy\n",
    "#N_TOP = 20 \n",
    "#full_df, top_codes = database_selection.filter_top_codes(df, 'ICD9', N_TOP, filter_empty = True)\n",
    "#df = full_df.head(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing leave icd-9 codes with their grandparent icd-9 code in the first level of the hierarchy\n",
    "\n",
    "Source: https://github.com/sirrice/icd9   \n",
    "The code above let's you see the ICD-9 hierarchy and traverse it, getting the parents (path) of a node, the children of a node, siblings, etc. (well documented in its README file).  \n",
    "\n",
    "From looking at the top of the hierarchy, these are the ICD9-codes that are in the first level of the hierarchy.\n",
    "```\n",
    "001-139 INFECTIOUS AND PARASITIC DISEASES \n",
    "140-239 NEOPLASMS \n",
    "240-279 ENDOCRINE, NUTRITIONAL AND METABOLIC DISEASES, AND IMMUNITY DISORDERS \n",
    "290-319 MENTAL DISORDERS \n",
    "320-389 DISEASES OF THE NERVOUS SYSTEM AND SENSE ORGANS \n",
    "390-459 DISEASES OF THE CIRCULATORY SYSTEM \n",
    "460-519 DISEASES OF THE RESPIRATORY SYSTEM \n",
    "520-579 DISEASES OF THE DIGESTIVE SYSTEM \n",
    "580-629 DISEASES OF THE GENITOURINARY SYSTEM \n",
    "630-679 COMPLICATIONS OF PREGNANCY, CHILDBIRTH, AND THE PUERPERIUM \n",
    "680-709 DISEASES OF THE SKIN AND SUBCUTANEOUS TISSUE \n",
    "710-739 DISEASES OF THE MUSCULOSKELETAL SYSTEM AND CONNECTIVE TISSUE \n",
    "760-779 CERTAIN CONDITIONS ORIGINATING IN THE PERINATAL PERIOD \n",
    "780-789 SYMPTOMS \n",
    "790-796 NONSPECIFIC ABNORMAL FINDINGS \n",
    "797 Senility without mention of psychosis\n",
    "798 Sudden death, cause unknown\n",
    "799 Other ill-defined and unknown causes of morbidity and mortality\n",
    "800-999 INJURY AND POISONING \n",
    "```\n",
    "\n",
    "The way that ICD9-codes are coded makes easy to find out which icd9-code code is the granparent in the first level,\n",
    "for example:\n",
    "```\n",
    "leave-code  code-at-first-level\n",
    "64833    -> 630-679\n",
    "4019     -> 390-459\n",
    "```\n",
    "\n",
    "The first three charachters of the leave icd9-code can be used to find out which is the grandparent icd-code in the first level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>ICD9</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109180</td>\n",
       "      <td>25962</td>\n",
       "      <td>2107-01-02 00:00:00</td>\n",
       "      <td>001-139 390-459 460-519 780-789 580-629 710-739</td>\n",
       "      <td>Admission Date:  [**2107-1-1**]     Discharge ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189225</td>\n",
       "      <td>23722</td>\n",
       "      <td>2108-03-04 00:00:00</td>\n",
       "      <td>760-779</td>\n",
       "      <td>Admission Date: [**2108-2-26**]        Dischar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>129143</td>\n",
       "      <td>3703</td>\n",
       "      <td>2173-08-21 00:00:00</td>\n",
       "      <td>240-279 390-459 290-319 460-519 520-579 320-38...</td>\n",
       "      <td>Admission Date:  [**2173-8-16**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>187236</td>\n",
       "      <td>29315</td>\n",
       "      <td>2174-05-11 00:00:00</td>\n",
       "      <td>390-459 710-739 290-319 520-579 800-999</td>\n",
       "      <td>Admission Date:  [**2174-5-3**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134128</td>\n",
       "      <td>28140</td>\n",
       "      <td>2105-06-03 00:00:00</td>\n",
       "      <td>240-279 390-459 520-579 780-789 140-239 580-629</td>\n",
       "      <td>Admission Date:  [**2105-5-30**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>146974</td>\n",
       "      <td>79915</td>\n",
       "      <td>2169-01-26 00:00:00</td>\n",
       "      <td>240-279 390-459 290-319 460-519 520-579 800-99...</td>\n",
       "      <td>Admission Date:  [**2168-12-25**]             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>132278</td>\n",
       "      <td>3792</td>\n",
       "      <td>2206-10-20 00:00:00</td>\n",
       "      <td>001-139 780-789 390-459 460-519 320-389</td>\n",
       "      <td>Admission Date:  [**2206-10-20**]             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>185036</td>\n",
       "      <td>43926</td>\n",
       "      <td>2197-05-24 00:00:00</td>\n",
       "      <td>240-279 390-459 290-319 460-519 520-579 800-99...</td>\n",
       "      <td>Admission Date:  [**2197-5-11**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>113161</td>\n",
       "      <td>13984</td>\n",
       "      <td>2138-08-15 00:00:00</td>\n",
       "      <td>290-319 800-999</td>\n",
       "      <td>Admission Date:  [**2138-7-30**]       Dischar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>167539</td>\n",
       "      <td>81407</td>\n",
       "      <td>2141-03-10 00:00:00</td>\n",
       "      <td>390-459 290-319 460-519 520-579 800-999 580-629</td>\n",
       "      <td>Admission Date:  [**2141-2-22**]              ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HADM_ID  SUBJECT_ID                 DATE  \\\n",
       "0   109180       25962  2107-01-02 00:00:00   \n",
       "1   189225       23722  2108-03-04 00:00:00   \n",
       "2   129143        3703  2173-08-21 00:00:00   \n",
       "3   187236       29315  2174-05-11 00:00:00   \n",
       "4   134128       28140  2105-06-03 00:00:00   \n",
       "5   146974       79915  2169-01-26 00:00:00   \n",
       "6   132278        3792  2206-10-20 00:00:00   \n",
       "7   185036       43926  2197-05-24 00:00:00   \n",
       "8   113161       13984  2138-08-15 00:00:00   \n",
       "9   167539       81407  2141-03-10 00:00:00   \n",
       "\n",
       "                                                ICD9  \\\n",
       "0    001-139 390-459 460-519 780-789 580-629 710-739   \n",
       "1                                            760-779   \n",
       "2  240-279 390-459 290-319 460-519 520-579 320-38...   \n",
       "3            390-459 710-739 290-319 520-579 800-999   \n",
       "4    240-279 390-459 520-579 780-789 140-239 580-629   \n",
       "5  240-279 390-459 290-319 460-519 520-579 800-99...   \n",
       "6            001-139 780-789 390-459 460-519 320-389   \n",
       "7  240-279 390-459 290-319 460-519 520-579 800-99...   \n",
       "8                                    290-319 800-999   \n",
       "9    390-459 290-319 460-519 520-579 800-999 580-629   \n",
       "\n",
       "                                                TEXT  \n",
       "0  Admission Date:  [**2107-1-1**]     Discharge ...  \n",
       "1  Admission Date: [**2108-2-26**]        Dischar...  \n",
       "2  Admission Date:  [**2173-8-16**]              ...  \n",
       "3  Admission Date:  [**2174-5-3**]              D...  \n",
       "4  Admission Date:  [**2105-5-30**]              ...  \n",
       "5  Admission Date:  [**2168-12-25**]             ...  \n",
       "6  Admission Date:  [**2206-10-20**]             ...  \n",
       "7  Admission Date:  [**2197-5-11**]              ...  \n",
       "8  Admission Date:  [**2138-7-30**]       Dischar...  \n",
       "9  Admission Date:  [**2141-2-22**]              ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ICD9_FIRST_LEVEL = [\n",
    "    '001-139','140-239','240-279','290-319', '320-389', '390-459','460-519', '520-579', '580-629', \n",
    "    '630-679', '680-709','710-739', '760-779', '780-789', '790-796', '797', '798', '799', '800-999' ]\n",
    "N_TOP = len(ICD9_FIRST_LEVEL)\n",
    "# replacing leave ICD9 codes with the grandparents\n",
    "df['ICD9'] = df['ICD9'].apply(lambda x: helpers.replace_with_grandparent_codes(x,ICD9_FIRST_LEVEL))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#preprocess icd9 codes\n",
    "top_codes = ICD9_FIRST_LEVEL\n",
    "labels = vectorization.vectorize_icd_column(df, 'ICD9', top_codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre process Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 45110\n",
      "Average note length: 1643.3459203\n",
      "Max note length: 7752\n",
      "Final Vocabulary: 45110\n",
      "Final Max Sequence Length: 5000\n"
     ]
    }
   ],
   "source": [
    "#preprocess notes\n",
    "MAX_VOCAB = None # to limit original number of words (None if no limit)\n",
    "MAX_SEQ_LENGTH = 5000 # to limit length of word sequence (None if no limit)\n",
    "df.TEXT = vectorization.clean_notes(df, 'TEXT')\n",
    "data, dictionary, MAX_VOCAB = vectorization.vectorize_notes(df.TEXT, MAX_VOCAB, verbose = True)\n",
    "data, MAX_SEQ_LENGTH = vectorization.pad_notes(data, MAX_SEQ_LENGTH)\n",
    "print(\"Final Vocabulary: %s\" % MAX_VOCAB)\n",
    "print(\"Final Max Sequence Length: %s\" % MAX_SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train: ', (3688, 5000), (3688, 19))\n",
      "('Validation: ', (1054, 5000), (1054, 19))\n",
      "('Test: ', (528, 5000), (528, 19))\n"
     ]
    }
   ],
   "source": [
    "#split sets\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = helpers.train_val_test_split(\n",
    "    data, labels, val_size=0.2, test_size=0.1, random_state=101)\n",
    "print(\"Train: \", X_train.shape, y_train.shape)\n",
    "print(\"Validation: \", X_val.shape, y_val.shape)\n",
    "print(\"Test: \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Delete temporary variables to free some memory\n",
    "del df, data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Vocabulary in notes:', 44646)\n",
      "('Vocabulary in original embedding:', 400000)\n",
      "('Vocabulary intersection:', 21960)\n"
     ]
    }
   ],
   "source": [
    "#creating embeddings\n",
    "EMBEDDING_LOC = '../data/glove.6B.100d.txt' # location of embedding\n",
    "EMBEDDING_DIM = 100 # given the glove that we chose\n",
    "EMBEDDING_MATRIX, embedding_dict = vectorization.embedding_matrix(EMBEDDING_LOC,\n",
    "                                                                  dictionary, EMBEDDING_DIM, verbose = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN for text classification\n",
    "\n",
    "Based on the following papers and links:\n",
    "* \"Convolutional Neural Networks for Sentence Classification\"   \n",
    "* \"A Sensitivity Analysis of (and Practitioners’ Guide to) Convolutional Neural Networks for Sentence Classification\"\n",
    "* http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/\n",
    "* https://github.com/alexander-rakhlin/CNN-for-Sentence-Classification-in-Keras/blob/master/sentiment_cnn.py\n",
    "* http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/\n",
    "* https://github.com/dennybritz/cnn-text-classification-tf/blob/master/text_cnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(icd9_cnn_model)\n",
    "#### build model\n",
    "model = icd9_cnn_model.build_icd9_cnn_model (input_seq_length=MAX_SEQ_LENGTH, max_vocab = MAX_VOCAB,\n",
    "                             external_embeddings = True, embedding_trainable =True,\n",
    "                             embedding_dim=EMBEDDING_DIM,embedding_matrix=EMBEDDING_MATRIX,\n",
    "                             num_filters = 100, filter_sizes=[2,3,4,5],\n",
    "                             training_dropout_keep_prob=0.9,\n",
    "                             num_classes=N_TOP )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3688 samples, validate on 1054 samples\n",
      "Epoch 1/5\n",
      "138s - loss: 2.1384 - acc: 0.7246 - val_loss: 0.7414 - val_acc: 0.7317\n",
      "Epoch 2/5\n",
      "138s - loss: 1.1068 - acc: 0.7299 - val_loss: 0.7165 - val_acc: 0.7317\n",
      "Epoch 3/5\n",
      "130s - loss: 0.8495 - acc: 0.7292 - val_loss: 0.7138 - val_acc: 0.7317\n",
      "Epoch 4/5\n",
      "129s - loss: 0.7827 - acc: 0.7288 - val_loss: 0.7113 - val_acc: 0.7317\n",
      "Epoch 5/5\n",
      "129s - loss: 0.7580 - acc: 0.7292 - val_loss: 0.7079 - val_acc: 0.7319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8db63be890>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=50, epochs=5, validation_data=(X_val, y_val), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_train = model.predict(X_train, batch_size=50)\n",
    "pred_dev = model.predict(X_val, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 scores\n",
      "threshold | training | dev  \n",
      "0.020:      0.539      0.532\n",
      "0.030:      0.574      0.563\n",
      "0.040:      0.598      0.587\n",
      "0.050:      0.620      0.601\n",
      "0.055:      0.630      0.606\n",
      "0.058:      0.634      0.611\n",
      "0.060:      0.636      0.612\n",
      "0.080:      0.615      0.584\n",
      "0.100:      0.495      0.474\n",
      "0.200:      0.035      0.032\n",
      "0.300:      0.015      0.010\n",
      "0.500:      0.001      0.001\n"
     ]
    }
   ],
   "source": [
    "def get_f1_score(y_true,y_hat,threshold, average):\n",
    "    hot_y = np.where(np.array(y_hat) > threshold, 1, 0)\n",
    "    return f1_score(np.array(y_true), hot_y, average=average)\n",
    "\n",
    "print 'F1 scores'\n",
    "print 'threshold | training | dev  '\n",
    "f1_score_average = 'micro'\n",
    "for threshold in [ 0.02, 0.03,0.04,0.05,0.055,0.058,0.06, 0.08, 0.1,0.2,0.3, 0.5]:\n",
    "    train_f1 = get_f1_score(y_train, pred_train,threshold,f1_score_average)\n",
    "    dev_f1 = get_f1_score(y_val, pred_dev,threshold,f1_score_average)\n",
    "    print '%1.3f:      %1.3f      %1.3f' % (threshold,train_f1, dev_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO: model for Thresholding\n",
    "Papers about Thresholding:    \n",
    "\n",
    "* \"Convolutional Neural Network using a Threshold Predictor for Multi-label Speech Act Classification\"   \n",
    "* \"A Study on Threshold Selection for Multi-label Classification\"   \n",
    "\n",
    "These papers mention they use a model for thresholding, but it is not the main topic:   \n",
    "* \"A Review on Multi-Label Learning Algorithms\"   \n",
    "* \"Large-scale Multi-label Text Classification—Revisiting Neural Networks\"*   \n",
    "* \"A multi-label convolutional neural network for automatic image annotation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results with external embeddings = True , no additional training,  top 20\n",
    "```\n",
    "F1 scores\n",
    "threshold | training | dev  \n",
    "0.020:      0.337      0.329\n",
    "0.030:      0.360      0.353\n",
    "0.040:      0.365      0.374\n",
    "0.050:      0.372      0.375\n",
    "0.055:      0.370      0.377\n",
    "0.058:      0.369      0.375\n",
    "0.060:      0.368      0.375\n",
    "0.080:      0.348      0.361\n",
    "0.100:      0.309      0.319\n",
    "0.200:      0.198      0.208\n",
    "0.300:      0.157      0.138\n",
    "0.500:      0.000      0.000\n",
    "```\n",
    "\n",
    "### Results with external embeddings = False, top 20\n",
    "```\n",
    "F1 scores\n",
    "threshold | training | dev  \n",
    "0.020:      0.288      0.300\n",
    "0.030:      0.327      0.322\n",
    "0.040:      0.371      0.363\n",
    "0.050:      0.380      0.391\n",
    "0.055:      0.412      0.383\n",
    "0.058:      0.403      0.394\n",
    "0.060:      0.394      0.389\n",
    "0.080:      0.385      0.390\n",
    "0.100:      0.229      0.225\n",
    "0.200:      0.000      0.000\n",
    "0.300:      0.000      0.000\n",
    "0.500:      0.000      0.000\n",
    "```\n",
    "\n",
    "### Results with external embedding and training them , top 20\n",
    "```\n",
    "F1 scores\n",
    "threshold | training | dev  \n",
    "0.020:      0.334      0.333\n",
    "0.030:      0.362      0.360\n",
    "0.040:      0.366      0.374\n",
    "0.050:      0.373      0.380\n",
    "0.055:      0.374      0.382\n",
    "0.058:      0.376      0.376\n",
    "0.060:      0.376      0.378\n",
    "0.080:      0.387      0.371\n",
    "0.100:      0.366      0.350\n",
    "0.200:      0.179      0.171\n",
    "0.300:      0.020      0.020\n",
    "0.500:      0.000      0.000\n",
    "\n",
    "```\n",
    "\n",
    "### Results with external Embeddings = False, top 10, \n",
    "We can compare this setup with the LSTM published in the paper \"Applying Deep Learning to ICD-9 Multi-label Classification from Medical Records\", they got a F1-score of about 0.4168, we are getting 0.447\n",
    "\n",
    "``` \n",
    "F1 scores\n",
    "threshold | training | dev  \n",
    "0.020:      0.399      0.407\n",
    "0.030:      0.399      0.407\n",
    "0.040:      0.399      0.407\n",
    "0.050:      0.408      0.413\n",
    "0.055:      0.433      0.420\n",
    "0.058:      0.437      0.430\n",
    "0.060:      0.432      0.427\n",
    "0.080:      0.501      0.463\n",
    "0.100:      0.446      0.463\n",
    "0.200:      0.206      0.066\n",
    "0.300:      0.000      0.000\n",
    "0.500:      0.000      0.000\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Notes:\n",
    "\n",
    "\n",
    "(1) There is a LSTM model by this paper: \"Applying Deep Learning to ICD-9 Multi-label Classification from Medical Records\" which did achieve a 42% F1-score. (https://cs224d.stanford.edu/reports/priyanka.pdf), but it only uses the top 10 icd9 codes. We are getting 46% (just running with 1000 notes so far)\n",
    "\n",
    "\n",
    "(2) The \"A Comparison of Rule-Based and Deep Learning Models for Patient Phenotyping\"  study did get a 70% F1-score, but they don't use the icd9-labels but phenotypes labels they annotated themselved (via a group of medical professionals). (https://arxiv.org/abs/1703.08705). There were ONLY 10 phenotypes.\n",
    "\n",
    "The discharge summaries are labeled with ICD9-codes that are leaves in the ICD9-hierarchy (which has hundreds of ICD9-codes), then maybe these leave nodes are too specific and difficult to predict, one experiment would be to replaced all the ICD9-codes with their parent in the second or third level in the hierarchy and see if predictions work better that way.   \n",
    "\n",
    "(3) our baseline with top 20 codes had a f1-score of 35% (assigning top 4 icd9 codes to all notes, using a CNN with no external embeddings is getting about 40% f1-score.. a little better than the baseline\n",
    "\n",
    "(4) Papers published and best practices report  that external embeddings improve considerable the model's performance.. maybe it is not the case here because of the medical terms..   \n",
    "\n",
    "(5) Fixed Thresholding doesn't work well for multilabel classifications, we can implement a model to choose the appropriate threshold for each record (see notes above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
