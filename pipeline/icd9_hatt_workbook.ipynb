{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## just a workbook, we will add more comments in the notebook for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "import random\n",
    "\n",
    "\n",
    "#keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, MaxPooling1D, Convolution1D, Embedding\n",
    "from keras.layers.merge import Concatenate\n",
    "\n",
    "# Custom functions\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import database_selection\n",
    "import vectorization\n",
    "import helpers\n",
    "import icd9_cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reading file\n",
    "full_df = pd.read_csv('../data/disch_notes_all_icd9.csv',\n",
    "                 names = ['HADM_ID', 'SUBJECT_ID', 'DATE', 'ICD9','TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5270, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>ICD9</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>134273</td>\n",
       "      <td>25127</td>\n",
       "      <td>2179-03-26 00:00:00</td>\n",
       "      <td>8080 80704 8058 83501 8020 42789 87340 87342</td>\n",
       "      <td>Admission Date:  [**2179-3-21**]       Dischar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120698</td>\n",
       "      <td>40729</td>\n",
       "      <td>2115-03-28 00:00:00</td>\n",
       "      <td>6826 5849 2760 42732 0389 99592 78552 5180 438...</td>\n",
       "      <td>Admission Date:  [**2115-3-24**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>157454</td>\n",
       "      <td>19851</td>\n",
       "      <td>2125-05-15 00:00:00</td>\n",
       "      <td>5070 40391 5856 99662 6822 07032 42832 4280 25...</td>\n",
       "      <td>Admission Date:  [**2125-5-7**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>109748</td>\n",
       "      <td>73473</td>\n",
       "      <td>2128-05-10 00:00:00</td>\n",
       "      <td>5070 51881 5849 5609 42731 2851 5781 185 2689 ...</td>\n",
       "      <td>Admission Date:  [**2128-5-7**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128866</td>\n",
       "      <td>67042</td>\n",
       "      <td>2122-07-21 00:00:00</td>\n",
       "      <td>2761 2930 34690 2768 27541 2753</td>\n",
       "      <td>Admission Date:  [**2122-7-19**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>153552</td>\n",
       "      <td>11460</td>\n",
       "      <td>2198-07-31 00:00:00</td>\n",
       "      <td>9582 4280 5990 5121 80502 4538 8088 70703 2948...</td>\n",
       "      <td>Admission Date:  [**2198-7-26**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>157346</td>\n",
       "      <td>9718</td>\n",
       "      <td>2106-04-24 00:00:00</td>\n",
       "      <td>431 4010 3315 496 34590</td>\n",
       "      <td>Admission Date:  [**2106-4-23**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>195031</td>\n",
       "      <td>32028</td>\n",
       "      <td>2191-03-01 00:00:00</td>\n",
       "      <td>48241 2536 4941 515 4019 53081 2859 34700 501</td>\n",
       "      <td>Admission Date:  [**2191-2-17**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>196730</td>\n",
       "      <td>28705</td>\n",
       "      <td>2169-05-24 00:00:00</td>\n",
       "      <td>769 7750</td>\n",
       "      <td>Admission Date: [**2169-5-22**]        Dischar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>120849</td>\n",
       "      <td>32649</td>\n",
       "      <td>2169-02-12 00:00:00</td>\n",
       "      <td>03842 5770 5070 42823 4280 57420 4359 2930 252...</td>\n",
       "      <td>Admission Date:  [**2169-1-27**]              ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HADM_ID  SUBJECT_ID                 DATE  \\\n",
       "0   134273       25127  2179-03-26 00:00:00   \n",
       "1   120698       40729  2115-03-28 00:00:00   \n",
       "2   157454       19851  2125-05-15 00:00:00   \n",
       "3   109748       73473  2128-05-10 00:00:00   \n",
       "4   128866       67042  2122-07-21 00:00:00   \n",
       "5   153552       11460  2198-07-31 00:00:00   \n",
       "6   157346        9718  2106-04-24 00:00:00   \n",
       "7   195031       32028  2191-03-01 00:00:00   \n",
       "8   196730       28705  2169-05-24 00:00:00   \n",
       "9   120849       32649  2169-02-12 00:00:00   \n",
       "\n",
       "                                                ICD9  \\\n",
       "0       8080 80704 8058 83501 8020 42789 87340 87342   \n",
       "1  6826 5849 2760 42732 0389 99592 78552 5180 438...   \n",
       "2  5070 40391 5856 99662 6822 07032 42832 4280 25...   \n",
       "3  5070 51881 5849 5609 42731 2851 5781 185 2689 ...   \n",
       "4                    2761 2930 34690 2768 27541 2753   \n",
       "5  9582 4280 5990 5121 80502 4538 8088 70703 2948...   \n",
       "6                            431 4010 3315 496 34590   \n",
       "7      48241 2536 4941 515 4019 53081 2859 34700 501   \n",
       "8                                           769 7750   \n",
       "9  03842 5770 5070 42823 4280 57420 4359 2930 252...   \n",
       "\n",
       "                                                TEXT  \n",
       "0  Admission Date:  [**2179-3-21**]       Dischar...  \n",
       "1  Admission Date:  [**2115-3-24**]              ...  \n",
       "2  Admission Date:  [**2125-5-7**]              D...  \n",
       "3  Admission Date:  [**2128-5-7**]              D...  \n",
       "4  Admission Date:  [**2122-7-19**]              ...  \n",
       "5  Admission Date:  [**2198-7-26**]              ...  \n",
       "6  Admission Date:  [**2106-4-23**]              ...  \n",
       "7  Admission Date:  [**2191-2-17**]              ...  \n",
       "8  Admission Date: [**2169-5-22**]        Dischar...  \n",
       "9  Admission Date:  [**2169-1-27**]              ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking just a subset of the records for developing models\n",
    "df = full_df.sample(frac=0.1).reset_index(drop=True)\n",
    "print df.shape\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre processing ICD 9 codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>ICD9</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>134273</td>\n",
       "      <td>25127</td>\n",
       "      <td>2179-03-26 00:00:00</td>\n",
       "      <td>390-459 800-999</td>\n",
       "      <td>Admission Date:  [**2179-3-21**]       Dischar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120698</td>\n",
       "      <td>40729</td>\n",
       "      <td>2115-03-28 00:00:00</td>\n",
       "      <td>240-279 001-139 290-319 390-459 680-709 460-51...</td>\n",
       "      <td>Admission Date:  [**2115-3-24**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>157454</td>\n",
       "      <td>19851</td>\n",
       "      <td>2125-05-15 00:00:00</td>\n",
       "      <td>240-279 001-139 290-319 390-459 680-709 460-51...</td>\n",
       "      <td>Admission Date:  [**2125-5-7**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>109748</td>\n",
       "      <td>73473</td>\n",
       "      <td>2128-05-10 00:00:00</td>\n",
       "      <td>240-279 390-459 290-319 460-519 520-579 140-23...</td>\n",
       "      <td>Admission Date:  [**2128-5-7**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128866</td>\n",
       "      <td>67042</td>\n",
       "      <td>2122-07-21 00:00:00</td>\n",
       "      <td>240-279 290-319 320-389</td>\n",
       "      <td>Admission Date:  [**2122-7-19**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>153552</td>\n",
       "      <td>11460</td>\n",
       "      <td>2198-07-31 00:00:00</td>\n",
       "      <td>240-279 680-709 390-459 290-319 460-519 800-99...</td>\n",
       "      <td>Admission Date:  [**2198-7-26**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>157346</td>\n",
       "      <td>9718</td>\n",
       "      <td>2106-04-24 00:00:00</td>\n",
       "      <td>390-459 460-519 320-389</td>\n",
       "      <td>Admission Date:  [**2106-4-23**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>195031</td>\n",
       "      <td>32028</td>\n",
       "      <td>2191-03-01 00:00:00</td>\n",
       "      <td>240-279 390-459 290-319 460-519 520-579 320-389</td>\n",
       "      <td>Admission Date:  [**2191-2-17**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>196730</td>\n",
       "      <td>28705</td>\n",
       "      <td>2169-05-24 00:00:00</td>\n",
       "      <td>760-779</td>\n",
       "      <td>Admission Date: [**2169-5-22**]        Dischar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>120849</td>\n",
       "      <td>32649</td>\n",
       "      <td>2169-02-12 00:00:00</td>\n",
       "      <td>240-279 001-139 390-459 290-319 460-519 520-579</td>\n",
       "      <td>Admission Date:  [**2169-1-27**]              ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HADM_ID  SUBJECT_ID                 DATE  \\\n",
       "0   134273       25127  2179-03-26 00:00:00   \n",
       "1   120698       40729  2115-03-28 00:00:00   \n",
       "2   157454       19851  2125-05-15 00:00:00   \n",
       "3   109748       73473  2128-05-10 00:00:00   \n",
       "4   128866       67042  2122-07-21 00:00:00   \n",
       "5   153552       11460  2198-07-31 00:00:00   \n",
       "6   157346        9718  2106-04-24 00:00:00   \n",
       "7   195031       32028  2191-03-01 00:00:00   \n",
       "8   196730       28705  2169-05-24 00:00:00   \n",
       "9   120849       32649  2169-02-12 00:00:00   \n",
       "\n",
       "                                                ICD9  \\\n",
       "0                                    390-459 800-999   \n",
       "1  240-279 001-139 290-319 390-459 680-709 460-51...   \n",
       "2  240-279 001-139 290-319 390-459 680-709 460-51...   \n",
       "3  240-279 390-459 290-319 460-519 520-579 140-23...   \n",
       "4                            240-279 290-319 320-389   \n",
       "5  240-279 680-709 390-459 290-319 460-519 800-99...   \n",
       "6                            390-459 460-519 320-389   \n",
       "7    240-279 390-459 290-319 460-519 520-579 320-389   \n",
       "8                                            760-779   \n",
       "9    240-279 001-139 390-459 290-319 460-519 520-579   \n",
       "\n",
       "                                                TEXT  \n",
       "0  Admission Date:  [**2179-3-21**]       Dischar...  \n",
       "1  Admission Date:  [**2115-3-24**]              ...  \n",
       "2  Admission Date:  [**2125-5-7**]              D...  \n",
       "3  Admission Date:  [**2128-5-7**]              D...  \n",
       "4  Admission Date:  [**2122-7-19**]              ...  \n",
       "5  Admission Date:  [**2198-7-26**]              ...  \n",
       "6  Admission Date:  [**2106-4-23**]              ...  \n",
       "7  Admission Date:  [**2191-2-17**]              ...  \n",
       "8  Admission Date: [**2169-5-22**]        Dischar...  \n",
       "9  Admission Date:  [**2169-1-27**]              ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ICD9_FIRST_LEVEL = [\n",
    "    '001-139','140-239','240-279','290-319', '320-389', '390-459','460-519', '520-579', '580-629', \n",
    "    '630-679', '680-709','710-739', '760-779', '780-789', '790-796', '797', '798', '799', '800-999' ]\n",
    "N_TOP = len(ICD9_FIRST_LEVEL)\n",
    "# replacing leave ICD9 codes with the grandparents\n",
    "df['ICD9'] = df['ICD9'].apply(lambda x: helpers.replace_with_grandparent_codes(x,ICD9_FIRST_LEVEL))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preprocess icd9 codes\n",
    "top_codes = ICD9_FIRST_LEVEL\n",
    "labels = vectorization.vectorize_icd_column(df, 'ICD9', top_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Notes\n",
    "\n",
    "The notes preprocessin here is a little different sice we want to keep dots and other characters to be able to split the notes into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for dataset\n",
    "    Every dataset is lower cased except\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"\\\\\", \"\", string)    \n",
    "    string = re.sub(r\"\\'\", \"\", string)    \n",
    "    string = re.sub(r\"\\\"\", \"\", string)    \n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "note_sentences = []\n",
    "notes = []\n",
    "\n",
    "for idx in range(df.shape[0]):\n",
    "    # for every note\n",
    "    text = clean_str(df[\"TEXT\"][idx].encode('ascii','ignore'))\n",
    "    notes.append(text)\n",
    "    sentences = tokenize.sent_tokenize(text)\n",
    "    note_sentences.append(sentences)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admission date:  [**2179-3-21**]       discharge date:  [**2179-3-25**] date of birth:   [**2131-5-1**]       sex:  m service:  trauma surgery history of present illness:  the patient is a 47-year-old man involved in a motor vehicle crash, car versus tree.',\n",
       " 'the motor vehicle collision was at a high speed estimated at 65 mph with the tree broken in half.',\n",
       " 'at the scene, the car was described as in a accordion.',\n",
       " 'there was unknown loss of consciousness with the accident.',\n",
       " 'after the accident, ems was activated, and the patient was taken to an outside medical center for evaluation.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "note_sentences[0][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what will be the MAX_SENTS and MAX_SENT_LENGTH ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of sentences in a note:  105.629981025\n",
      "Max number of sentences in a note:  586\n"
     ]
    }
   ],
   "source": [
    "note_sentences_length =[len(x) for x in note_sentences]\n",
    "print \"Average number of sentences in a note: \", np.mean(note_sentences_length)  \n",
    "print \"Max number of sentences in a note: \", max(note_sentences_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.array(note_sentences_length) > 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of words in a sentence:  16.9302998186\n",
      "Max number of words in a sentence:  5456\n"
     ]
    }
   ],
   "source": [
    "sentence_flat_list = [sentence for note_sentence in note_sentences for sentence in note_sentence]\n",
    "sentence_words_length =[len(text_to_word_sequence(sentence)) for sentence in sentence_flat_list]\n",
    "print \"Average number of words in a sentence: \", np.mean(sentence_words_length)  \n",
    "print \"Max number of words in a sentence: \", max(sentence_words_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1633"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.array(sentence_words_length) > 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zenla/anaconda2/lib/python2.7/site-packages/keras/preprocessing/text.py:139: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    }
   ],
   "source": [
    "MAX_NB_WORDS = None\n",
    "MAX_SENTS = 300\n",
    "MAX_SENT_LENGTH  = 250\n",
    "\n",
    "MAX_VOCAB = None # to limit original number of words (None if no limit)\n",
    "tokenizer = Tokenizer(nb_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(notes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = len(tokenizer.word_index)  #vocabulary length\n",
    "note_matrix = np.zeros((len(notes), MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\n",
    "\n",
    "for i, one_note_sentences in enumerate(note_sentences):\n",
    "    for j, sentence in enumerate(one_note_sentences):\n",
    "        if j< MAX_SENTS:\n",
    "            wordTokens = text_to_word_sequence(sentence)\n",
    "            k=0\n",
    "            for _, word in enumerate(wordTokens):\n",
    "                if k<MAX_SENT_LENGTH and tokenizer.word_index[word]<MAX_NB_WORDS:\n",
    "                    note_matrix[i,j,k] = tokenizer.word_index[word]\n",
    "                    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  55,   57, 1365,   13,  186,   32,   57, 1365,   13,   83,   57,\n",
       "          3,  257, 1668,   15,    6,  280,  164,  119, 1057,  203,   44,\n",
       "          3,  154,  260,    1,   20,   19,    8, 1389,  190,  265, 1084,\n",
       "       2026,   11,    8, 1163, 3644, 5607, 1979, 1911, 4221,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "note_matrix[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Vocabulary in notes:', 66721)\n",
      "('Vocabulary in original embedding:', 400000)\n",
      "('Vocabulary intersection:', 25421)\n"
     ]
    }
   ],
   "source": [
    "#creating embeddings\n",
    "EMBEDDING_LOC = '../data/glove.6B.100d.txt' # location of embedding\n",
    "EMBEDDING_DIM = 100 # given the glove that we chose\n",
    "EMBEDDING_MATRIX, embedding_dict = vectorization.embedding_matrix(EMBEDDING_LOC,\n",
    "                                                                  dictionary, EMBEDDING_DIM, verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train: ', (3688, 300, 250), (3688, 19))\n",
      "('Validation: ', (1054, 300, 250), (1054, 19))\n",
      "('Test: ', (528, 300, 250), (528, 19))\n"
     ]
    }
   ],
   "source": [
    "#split sets\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = helpers.train_val_test_split(\n",
    "    note_matrix, labels, val_size=0.2, test_size=0.1, random_state=101)\n",
    "print(\"Train: \", X_train.shape, y_train.shape)\n",
    "print(\"Validation: \", X_val.shape, y_val.shape)\n",
    "print(\"Test: \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Attention NN\n",
    "based on paper: Hierarchical Attention networks for document classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import hatt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hatt_model.py:29: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  output_attention_mul = merge([inputs, a_probs], name='attention_mul', mode='mul')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 250, 200)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_8 (InputLayer)             (None, 250)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)          (None, 250, 100)      6672200     input_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional)  (None, 250, 200)      120600      embedding_8[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistribu (None, 250, 200)      40200       bidirectional_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "permute_8 (Permute)              (None, 200, 250)      0           time_distributed_8[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)              (None, 200, 250)      0           permute_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_16 (Dense)                 (None, 200, 250)      62750       reshape_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dim_reduction (Lambda)           (None, 250)           0           dense_16[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "repeat_vector_8 (RepeatVector)   (None, 200, 250)      0           dim_reduction[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "attention_vec (Permute)          (None, 250, 200)      0           repeat_vector_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "attention_mul (Merge)            (None, 250, 200)      0           time_distributed_8[0][0]         \n",
      "                                                                   attention_vec[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (None, 200)           0           attention_mul[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 6,895,750\n",
      "Trainable params: 6,895,750\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "(?, 300, 200)\n",
      "model fitting - Hierachical Attention GRU\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_9 (InputLayer)             (None, 300, 250)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistribu (None, 300, 200)      6895750     input_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional)  (None, 300, 200)      180600      time_distributed_9[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistrib (None, 300, 200)      40200       bidirectional_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "permute_9 (Permute)              (None, 200, 300)      0           time_distributed_10[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)              (None, 200, 300)      0           permute_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_18 (Dense)                 (None, 200, 300)      90300       reshape_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dim_reduction (Lambda)           (None, 300)           0           dense_18[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "repeat_vector_9 (RepeatVector)   (None, 200, 300)      0           dim_reduction[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "attention_vec (Permute)          (None, 300, 200)      0           repeat_vector_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "attention_mul (Merge)            (None, 300, 200)      0           time_distributed_10[0][0]        \n",
      "                                                                   attention_vec[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)                (None, 200)           0           attention_mul[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "preds (Dense)                    (None, 19)            3819        lambda_2[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 7,210,669\n",
      "Trainable params: 7,210,669\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "reload(hatt_model)\n",
    "h_att_model = hatt_model.build_gru_att_model(MAX_SENTS, MAX_SENT_LENGTH, \n",
    "                         max_vocab=MAX_NB_WORDS, embedding_dim=EMBEDDING_DIM , embedding_matrix=EMBEDDING_MATRIX,\n",
    "                         num_classes=N_TOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3688 samples, validate on 1054 samples\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "h_att_model.fit(X_train, y_train, batch_size=50, epochs=5, validation_data=(X_val, y_val), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
