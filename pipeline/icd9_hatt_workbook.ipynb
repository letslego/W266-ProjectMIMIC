{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## just a workbook, we will add more comments in the notebook for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "import random\n",
    "\n",
    "\n",
    "#keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, MaxPooling1D, Convolution1D, Embedding\n",
    "from keras.layers.merge import Concatenate\n",
    "\n",
    "# Custom functions\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import database_selection\n",
    "import vectorization\n",
    "import helpers\n",
    "import icd9_cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reading file\n",
    "full_df = pd.read_csv('../data/disch_notes_all_icd9.csv',\n",
    "                 names = ['HADM_ID', 'SUBJECT_ID', 'DATE', 'ICD9','TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5270, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>ICD9</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135478</td>\n",
       "      <td>3328</td>\n",
       "      <td>2187-12-25 00:00:00</td>\n",
       "      <td>25083 9974 99686 5601 29281 25043 4019 2449</td>\n",
       "      <td>Admission Date:  [**2187-12-12**]       Discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115742</td>\n",
       "      <td>25540</td>\n",
       "      <td>2178-01-13 00:00:00</td>\n",
       "      <td>9351 5304 51881 4280 42731 9982 4820 48241 349...</td>\n",
       "      <td>Admission Date:  [**2177-12-20**]             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>135467</td>\n",
       "      <td>83124</td>\n",
       "      <td>2104-10-05 00:00:00</td>\n",
       "      <td>2762 42823 41401 2411 2767 25052 36201 25042 5...</td>\n",
       "      <td>Admission Date:  [**2104-10-3**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>148209</td>\n",
       "      <td>10280</td>\n",
       "      <td>2181-03-07 00:00:00</td>\n",
       "      <td>4822 41071 99662 03811 5121 99591 53240 5180 5...</td>\n",
       "      <td>Admission Date:  [**2181-2-6**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>193597</td>\n",
       "      <td>15450</td>\n",
       "      <td>2147-07-04 00:00:00</td>\n",
       "      <td>4019 28521 4401 412 4275 5845 4280 2762 5859 4...</td>\n",
       "      <td>Admission Date:  [**2147-7-3**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>131754</td>\n",
       "      <td>79655</td>\n",
       "      <td>2125-04-14 00:00:00</td>\n",
       "      <td>56081 2762 5715 41401 4142 412 25000 40390 585...</td>\n",
       "      <td>Admission Date:  [**2125-4-10**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>174772</td>\n",
       "      <td>53787</td>\n",
       "      <td>2160-10-11 00:00:00</td>\n",
       "      <td>49322 5849 27651 4659 40390 5859 25002 2724 56...</td>\n",
       "      <td>Admission Date:  [**2160-10-7**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>136013</td>\n",
       "      <td>60106</td>\n",
       "      <td>2145-02-12 00:00:00</td>\n",
       "      <td>51884 0389 78552 51909 5070 99592 49390 5715 4...</td>\n",
       "      <td>Name:  [**Known lastname 5685**],[**Known firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>117578</td>\n",
       "      <td>5503</td>\n",
       "      <td>2168-12-20 00:00:00</td>\n",
       "      <td>41401 4139 9973 486 2720 4019 412</td>\n",
       "      <td>Admission Date:  [**2168-12-14**]       Discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>167023</td>\n",
       "      <td>84615</td>\n",
       "      <td>2109-09-22 00:00:00</td>\n",
       "      <td>5552 56722 0389 99591 5772 56981 2841 78959 51...</td>\n",
       "      <td>Admission Date:  [**2109-9-14**]              ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HADM_ID  SUBJECT_ID                 DATE  \\\n",
       "0   135478        3328  2187-12-25 00:00:00   \n",
       "1   115742       25540  2178-01-13 00:00:00   \n",
       "2   135467       83124  2104-10-05 00:00:00   \n",
       "3   148209       10280  2181-03-07 00:00:00   \n",
       "4   193597       15450  2147-07-04 00:00:00   \n",
       "5   131754       79655  2125-04-14 00:00:00   \n",
       "6   174772       53787  2160-10-11 00:00:00   \n",
       "7   136013       60106  2145-02-12 00:00:00   \n",
       "8   117578        5503  2168-12-20 00:00:00   \n",
       "9   167023       84615  2109-09-22 00:00:00   \n",
       "\n",
       "                                                ICD9  \\\n",
       "0        25083 9974 99686 5601 29281 25043 4019 2449   \n",
       "1  9351 5304 51881 4280 42731 9982 4820 48241 349...   \n",
       "2  2762 42823 41401 2411 2767 25052 36201 25042 5...   \n",
       "3  4822 41071 99662 03811 5121 99591 53240 5180 5...   \n",
       "4  4019 28521 4401 412 4275 5845 4280 2762 5859 4...   \n",
       "5  56081 2762 5715 41401 4142 412 25000 40390 585...   \n",
       "6  49322 5849 27651 4659 40390 5859 25002 2724 56...   \n",
       "7  51884 0389 78552 51909 5070 99592 49390 5715 4...   \n",
       "8                  41401 4139 9973 486 2720 4019 412   \n",
       "9  5552 56722 0389 99591 5772 56981 2841 78959 51...   \n",
       "\n",
       "                                                TEXT  \n",
       "0  Admission Date:  [**2187-12-12**]       Discha...  \n",
       "1  Admission Date:  [**2177-12-20**]             ...  \n",
       "2  Admission Date:  [**2104-10-3**]              ...  \n",
       "3  Admission Date:  [**2181-2-6**]              D...  \n",
       "4  Admission Date:  [**2147-7-3**]              D...  \n",
       "5  Admission Date:  [**2125-4-10**]              ...  \n",
       "6  Admission Date:  [**2160-10-7**]              ...  \n",
       "7  Name:  [**Known lastname 5685**],[**Known firs...  \n",
       "8  Admission Date:  [**2168-12-14**]       Discha...  \n",
       "9  Admission Date:  [**2109-9-14**]              ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking just a subset of the records for developing models\n",
    "df = full_df.sample(frac=0.1).reset_index(drop=True)\n",
    "print df.shape\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre processing ICD 9 codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>ICD9</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135478</td>\n",
       "      <td>3328</td>\n",
       "      <td>2187-12-25 00:00:00</td>\n",
       "      <td>240-279 390-459 290-319 520-579 800-999</td>\n",
       "      <td>Admission Date:  [**2187-12-12**]       Discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115742</td>\n",
       "      <td>25540</td>\n",
       "      <td>2178-01-13 00:00:00</td>\n",
       "      <td>240-279 390-459 290-319 460-519 520-579 800-99...</td>\n",
       "      <td>Admission Date:  [**2177-12-20**]             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>135467</td>\n",
       "      <td>83124</td>\n",
       "      <td>2104-10-05 00:00:00</td>\n",
       "      <td>240-279 390-459 520-579 320-389 580-629 710-739</td>\n",
       "      <td>Admission Date:  [**2104-10-3**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>148209</td>\n",
       "      <td>10280</td>\n",
       "      <td>2181-03-07 00:00:00</td>\n",
       "      <td>001-139 390-459 290-319 460-519 520-579 800-99...</td>\n",
       "      <td>Admission Date:  [**2181-2-6**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>193597</td>\n",
       "      <td>15450</td>\n",
       "      <td>2147-07-04 00:00:00</td>\n",
       "      <td>580-629 240-279 390-459 290-319</td>\n",
       "      <td>Admission Date:  [**2147-7-3**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>131754</td>\n",
       "      <td>79655</td>\n",
       "      <td>2125-04-14 00:00:00</td>\n",
       "      <td>240-279 580-629 390-459 290-319 520-579</td>\n",
       "      <td>Admission Date:  [**2125-4-10**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>174772</td>\n",
       "      <td>53787</td>\n",
       "      <td>2160-10-11 00:00:00</td>\n",
       "      <td>240-279 390-459 290-319 460-519 520-579 580-629</td>\n",
       "      <td>Admission Date:  [**2160-10-7**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>136013</td>\n",
       "      <td>60106</td>\n",
       "      <td>2145-02-12 00:00:00</td>\n",
       "      <td>240-279 001-139 390-459 290-319 460-519 520-57...</td>\n",
       "      <td>Name:  [**Known lastname 5685**],[**Known firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>117578</td>\n",
       "      <td>5503</td>\n",
       "      <td>2168-12-20 00:00:00</td>\n",
       "      <td>240-279 390-459 460-519 800-999</td>\n",
       "      <td>Admission Date:  [**2168-12-14**]       Discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>167023</td>\n",
       "      <td>84615</td>\n",
       "      <td>2109-09-22 00:00:00</td>\n",
       "      <td>240-279 001-139 290-319 460-519 520-579 800-99...</td>\n",
       "      <td>Admission Date:  [**2109-9-14**]              ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HADM_ID  SUBJECT_ID                 DATE  \\\n",
       "0   135478        3328  2187-12-25 00:00:00   \n",
       "1   115742       25540  2178-01-13 00:00:00   \n",
       "2   135467       83124  2104-10-05 00:00:00   \n",
       "3   148209       10280  2181-03-07 00:00:00   \n",
       "4   193597       15450  2147-07-04 00:00:00   \n",
       "5   131754       79655  2125-04-14 00:00:00   \n",
       "6   174772       53787  2160-10-11 00:00:00   \n",
       "7   136013       60106  2145-02-12 00:00:00   \n",
       "8   117578        5503  2168-12-20 00:00:00   \n",
       "9   167023       84615  2109-09-22 00:00:00   \n",
       "\n",
       "                                                ICD9  \\\n",
       "0            240-279 390-459 290-319 520-579 800-999   \n",
       "1  240-279 390-459 290-319 460-519 520-579 800-99...   \n",
       "2    240-279 390-459 520-579 320-389 580-629 710-739   \n",
       "3  001-139 390-459 290-319 460-519 520-579 800-99...   \n",
       "4                    580-629 240-279 390-459 290-319   \n",
       "5            240-279 580-629 390-459 290-319 520-579   \n",
       "6    240-279 390-459 290-319 460-519 520-579 580-629   \n",
       "7  240-279 001-139 390-459 290-319 460-519 520-57...   \n",
       "8                    240-279 390-459 460-519 800-999   \n",
       "9  240-279 001-139 290-319 460-519 520-579 800-99...   \n",
       "\n",
       "                                                TEXT  \n",
       "0  Admission Date:  [**2187-12-12**]       Discha...  \n",
       "1  Admission Date:  [**2177-12-20**]             ...  \n",
       "2  Admission Date:  [**2104-10-3**]              ...  \n",
       "3  Admission Date:  [**2181-2-6**]              D...  \n",
       "4  Admission Date:  [**2147-7-3**]              D...  \n",
       "5  Admission Date:  [**2125-4-10**]              ...  \n",
       "6  Admission Date:  [**2160-10-7**]              ...  \n",
       "7  Name:  [**Known lastname 5685**],[**Known firs...  \n",
       "8  Admission Date:  [**2168-12-14**]       Discha...  \n",
       "9  Admission Date:  [**2109-9-14**]              ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ICD9_FIRST_LEVEL = [\n",
    "    '001-139','140-239','240-279','290-319', '320-389', '390-459','460-519', '520-579', '580-629', \n",
    "    '630-679', '680-709','710-739', '760-779', '780-789', '790-796', '797', '798', '799', '800-999' ]\n",
    "N_TOP = len(ICD9_FIRST_LEVEL)\n",
    "# replacing leave ICD9 codes with the grandparents\n",
    "df['ICD9'] = df['ICD9'].apply(lambda x: helpers.replace_with_grandparent_codes(x,ICD9_FIRST_LEVEL))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preprocess icd9 codes\n",
    "top_codes = ICD9_FIRST_LEVEL\n",
    "labels = vectorization.vectorize_icd_column(df, 'ICD9', top_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Notes\n",
    "\n",
    "The notes preprocessin here is a little different sice we want to keep dots and other characters to be able to split the notes into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for dataset\n",
    "    Every dataset is lower cased except\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"\\\\\", \"\", string)    \n",
    "    string = re.sub(r\"\\'\", \"\", string)    \n",
    "    string = re.sub(r\"\\\"\", \"\", string)    \n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "note_sentences = []\n",
    "notes = []\n",
    "\n",
    "for idx in range(df.shape[0]):\n",
    "    # for every note\n",
    "    text = clean_str(df[\"TEXT\"][idx].encode('ascii','ignore'))\n",
    "    notes.append(text)\n",
    "    sentences = tokenize.sent_tokenize(text)\n",
    "    note_sentences.append(sentences)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admission date:  [**2187-12-12**]       discharge date:  [**2187-12-25**] date of birth:   [**2141-2-6**]       sex:  m service:  1 chief complaint: 1.  insulin dependent diabetes mellitus.',\n",
       " '2.  pancreas after a kidney transplant.',\n",
       " 'history of present illness:   the patient is a 46 year old male status post renal transplant for insulin dependent diabetes mellitus now here for a pancreas after kidney transplant.',\n",
       " 'the patient denies nausea or vomiting.',\n",
       " 'the patient denies recent history of the flu or lymphadenopathy.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "note_sentences[0][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what will be the MAX_SENTS and MAX_SENT_LENGTH ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of sentences in a note:  104.415749526\n",
      "Max number of sentences in a note:  531\n"
     ]
    }
   ],
   "source": [
    "note_sentences_length =[len(x) for x in note_sentences]\n",
    "print \"Average number of sentences in a note: \", np.mean(note_sentences_length)  \n",
    "print \"Max number of sentences in a note: \", max(note_sentences_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.array(note_sentences_length) > 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(note_sentences[0][0].split ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "8\n",
      "10\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# number of words in a sentence\n",
    "print len(note_sentences[0][0].split())\n",
    "print len(note_sentences[0][10].split())\n",
    "print len(note_sentences[1][5].split())\n",
    "print len(note_sentences[1][10].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of words in a sentence:  16.9173534495\n",
      "Max number of words in a sentence:  2624\n"
     ]
    }
   ],
   "source": [
    "sentence_flat_list = [sentence for note_sentence in note_sentences for sentence in note_sentence]\n",
    "sentence_words_length =[len(text_to_word_sequence(sentence)) for sentence in sentence_flat_list]\n",
    "print \"Average number of words in a sentence: \", np.mean(sentence_words_length)  \n",
    "print \"Max number of words in a sentence: \", max(sentence_words_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1595"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.array(sentence_words_length) > 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zenla/anaconda2/lib/python2.7/site-packages/keras/preprocessing/text.py:139: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    }
   ],
   "source": [
    "MAX_NB_WORDS = None\n",
    "MAX_SENTS = 300\n",
    "MAX_SENT_LENGTH  = 250\n",
    "\n",
    "MAX_VOCAB = None # to limit original number of words (None if no limit)\n",
    "tokenizer = Tokenizer(nb_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(notes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = len(tokenizer.word_index)  #vocabulary length\n",
    "note_matrix = np.zeros((len(notes), MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\n",
    "\n",
    "for i, one_note_sentences in enumerate(note_sentences):\n",
    "    for j, sentence in enumerate(one_note_sentences):\n",
    "        if j< MAX_SENTS:\n",
    "            wordTokens = text_to_word_sequence(sentence)\n",
    "            k=0\n",
    "            for _, word in enumerate(wordTokens):\n",
    "                if k<MAX_SENT_LENGTH and tokenizer.word_index[word]<MAX_NB_WORDS:\n",
    "                    note_matrix[i,j,k] = tokenizer.word_index[word]\n",
    "                    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  54,   56, 1258,   41,   41,   32,   56, 1258,   41,   84,   56,\n",
       "          4,  253, 1230,    9,   22,  279,  165,  121,    6,  352,  342,\n",
       "          6,  317, 1602,  465, 1063,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "note_matrix[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Vocabulary in notes:', 66494)\n",
      "('Vocabulary in original embedding:', 400000)\n",
      "('Vocabulary intersection:', 25436)\n"
     ]
    }
   ],
   "source": [
    "#creating embeddings\n",
    "EMBEDDING_LOC = '../data/glove.6B.100d.txt' # location of embedding\n",
    "EMBEDDING_DIM = 100 # given the glove that we chose\n",
    "EMBEDDING_MATRIX, embedding_dict = vectorization.embedding_matrix(EMBEDDING_LOC,\n",
    "                                                                  dictionary, EMBEDDING_DIM, verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train: ', (3688, 300, 250), (3688, 19))\n",
      "('Validation: ', (1054, 300, 250), (1054, 19))\n",
      "('Test: ', (528, 300, 250), (528, 19))\n"
     ]
    }
   ],
   "source": [
    "#split sets\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = helpers.train_val_test_split(\n",
    "    note_matrix, labels, val_size=0.2, test_size=0.1, random_state=101)\n",
    "print(\"Train: \", X_train.shape, y_train.shape)\n",
    "print(\"Validation: \", X_val.shape, y_val.shape)\n",
    "print(\"Test: \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Attention NN\n",
    "based on paper: Hierarchical Attention networks for document classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import hatt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hatt_model.py:28: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  output_attention_mul = merge([inputs, a_probs], name='attention_mul', mode='mul')\n",
      "/home/zenla/anaconda2/lib/python2.7/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitting - Hierachical Attention GRU\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 300, 250)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistribu (None, 300, 50000)    6873050     input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional)  (None, 300, 200)      30060600    time_distributed_2[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistribu (None, 300, 200)      40200       bidirectional_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "permute_2 (Permute)              (None, 200, 300)      0           time_distributed_3[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)              (None, 200, 300)      0           permute_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 200, 300)      90300       reshape_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "attention_vec (Permute)          (None, 300, 200)      0           dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "attention_mul (Merge)            (None, 300, 200)      0           time_distributed_3[0][0]         \n",
      "                                                                   attention_vec[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 60000)         0           attention_mul[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "preds (Dense)                    (None, 19)            1140019     flatten_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 38,204,169\n",
      "Trainable params: 38,204,169\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "reload(hatt_model)\n",
    "h_att_model = hatt_model.build_gru_att_model(MAX_SENTS, MAX_SENT_LENGTH, \n",
    "                         max_vocab=MAX_NB_WORDS, embedding_dim=EMBEDDING_DIM , embedding_matrix=EMBEDDING_MATRIX,\n",
    "                         num_classes=N_TOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3688 samples, validate on 1054 samples\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "h_att_model.fit(X_train, y_train, batch_size=50, epochs=1, validation_data=(X_val, y_val), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
