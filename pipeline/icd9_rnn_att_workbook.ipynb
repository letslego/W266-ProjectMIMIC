{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## just a workbook, we will add more comments in the notebook for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "import random\n",
    "\n",
    "\n",
    "#keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, MaxPooling1D, Convolution1D, Embedding, LSTM, Bidirectional\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "# Custom functions\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import database_selection\n",
    "import vectorization\n",
    "import helpers\n",
    "import icd9_cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reading file\n",
    "full_df = pd.read_csv('../data/disch_notes_all_icd9.csv',\n",
    "                 names = ['HADM_ID', 'SUBJECT_ID', 'DATE', 'ICD9','TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5270, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>ICD9</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142565</td>\n",
       "      <td>56446</td>\n",
       "      <td>2198-03-12 00:00:00</td>\n",
       "      <td>0389 486 5849 78552 2761 5119 5109 2910 51881 ...</td>\n",
       "      <td>Admission Date:  [**2198-2-28**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>158269</td>\n",
       "      <td>62415</td>\n",
       "      <td>2122-08-13 00:00:00</td>\n",
       "      <td>2113 56729 9986 42832 4280 99749 99859 42731 4...</td>\n",
       "      <td>Admission Date:  [**2122-8-1**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>160831</td>\n",
       "      <td>66362</td>\n",
       "      <td>2106-08-02 00:00:00</td>\n",
       "      <td>5761 5856 40391 57450 25000 317</td>\n",
       "      <td>Admission Date:  [**2106-7-28**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142640</td>\n",
       "      <td>10254</td>\n",
       "      <td>2192-01-08 00:00:00</td>\n",
       "      <td>5781 42731 5070 70703 4242 42830 5845 5990 276...</td>\n",
       "      <td>Admission Date:  [**2191-12-12**]             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132744</td>\n",
       "      <td>9061</td>\n",
       "      <td>2198-10-17 00:00:00</td>\n",
       "      <td>99662 0388 486 5070 1179 56981 56081 5990 9985...</td>\n",
       "      <td>Admission Date:  [**2198-8-21**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>107362</td>\n",
       "      <td>22087</td>\n",
       "      <td>2140-12-28 00:00:00</td>\n",
       "      <td>43311 34290 5990 5997 4414 2765 2449 4019 2720</td>\n",
       "      <td>Admission Date:  [**2140-12-19**]       Discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>110703</td>\n",
       "      <td>14124</td>\n",
       "      <td>2120-10-19 00:00:00</td>\n",
       "      <td>9654 5070 9651 9690 9694 96561 9630 9693</td>\n",
       "      <td>Admission Date:  [**2120-10-15**]       Discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>172000</td>\n",
       "      <td>51027</td>\n",
       "      <td>2165-01-26 00:00:00</td>\n",
       "      <td>5849 4275 34830 2762 40311 42822 25080 4280 58...</td>\n",
       "      <td>Admission Date:  [**2165-1-10**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>125657</td>\n",
       "      <td>81038</td>\n",
       "      <td>2144-03-20 00:00:00</td>\n",
       "      <td>56081 5849 5990 04112 78830 28850 42789</td>\n",
       "      <td>Admission Date:  [**2144-3-10**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>198664</td>\n",
       "      <td>18288</td>\n",
       "      <td>2113-01-17 00:00:00</td>\n",
       "      <td>1570 1962 49320 5772 57410 4019 2749</td>\n",
       "      <td>Admission Date:  [**2113-1-10**]              ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HADM_ID  SUBJECT_ID                 DATE  \\\n",
       "0   142565       56446  2198-03-12 00:00:00   \n",
       "1   158269       62415  2122-08-13 00:00:00   \n",
       "2   160831       66362  2106-08-02 00:00:00   \n",
       "3   142640       10254  2192-01-08 00:00:00   \n",
       "4   132744        9061  2198-10-17 00:00:00   \n",
       "5   107362       22087  2140-12-28 00:00:00   \n",
       "6   110703       14124  2120-10-19 00:00:00   \n",
       "7   172000       51027  2165-01-26 00:00:00   \n",
       "8   125657       81038  2144-03-20 00:00:00   \n",
       "9   198664       18288  2113-01-17 00:00:00   \n",
       "\n",
       "                                                ICD9  \\\n",
       "0  0389 486 5849 78552 2761 5119 5109 2910 51881 ...   \n",
       "1  2113 56729 9986 42832 4280 99749 99859 42731 4...   \n",
       "2                    5761 5856 40391 57450 25000 317   \n",
       "3  5781 42731 5070 70703 4242 42830 5845 5990 276...   \n",
       "4  99662 0388 486 5070 1179 56981 56081 5990 9985...   \n",
       "5     43311 34290 5990 5997 4414 2765 2449 4019 2720   \n",
       "6           9654 5070 9651 9690 9694 96561 9630 9693   \n",
       "7  5849 4275 34830 2762 40311 42822 25080 4280 58...   \n",
       "8            56081 5849 5990 04112 78830 28850 42789   \n",
       "9               1570 1962 49320 5772 57410 4019 2749   \n",
       "\n",
       "                                                TEXT  \n",
       "0  Admission Date:  [**2198-2-28**]              ...  \n",
       "1  Admission Date:  [**2122-8-1**]              D...  \n",
       "2  Admission Date:  [**2106-7-28**]              ...  \n",
       "3  Admission Date:  [**2191-12-12**]             ...  \n",
       "4  Admission Date:  [**2198-8-21**]              ...  \n",
       "5  Admission Date:  [**2140-12-19**]       Discha...  \n",
       "6  Admission Date:  [**2120-10-15**]       Discha...  \n",
       "7  Admission Date:  [**2165-1-10**]              ...  \n",
       "8  Admission Date:  [**2144-3-10**]              ...  \n",
       "9  Admission Date:  [**2113-1-10**]              ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking just a subset of the records for developing models\n",
    "df = full_df.sample(frac=0.1).reset_index(drop=True)\n",
    "print df.shape\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre processing ICD 9 codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>ICD9</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142565</td>\n",
       "      <td>56446</td>\n",
       "      <td>2198-03-12 00:00:00</td>\n",
       "      <td>240-279 001-139 390-459 290-319 460-519 800-99...</td>\n",
       "      <td>Admission Date:  [**2198-2-28**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>158269</td>\n",
       "      <td>62415</td>\n",
       "      <td>2122-08-13 00:00:00</td>\n",
       "      <td>240-279 390-459 290-319 460-519 520-579 800-99...</td>\n",
       "      <td>Admission Date:  [**2122-8-1**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>160831</td>\n",
       "      <td>66362</td>\n",
       "      <td>2106-08-02 00:00:00</td>\n",
       "      <td>580-629 240-279 390-459 290-319 520-579</td>\n",
       "      <td>Admission Date:  [**2106-7-28**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142640</td>\n",
       "      <td>10254</td>\n",
       "      <td>2192-01-08 00:00:00</td>\n",
       "      <td>240-279 001-139 290-319 390-459 680-709 460-51...</td>\n",
       "      <td>Admission Date:  [**2191-12-12**]             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132744</td>\n",
       "      <td>9061</td>\n",
       "      <td>2198-10-17 00:00:00</td>\n",
       "      <td>240-279 760-779 001-139 390-459 460-519 520-57...</td>\n",
       "      <td>Admission Date:  [**2198-8-21**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>107362</td>\n",
       "      <td>22087</td>\n",
       "      <td>2140-12-28 00:00:00</td>\n",
       "      <td>580-629 240-279 390-459 320-389</td>\n",
       "      <td>Admission Date:  [**2140-12-19**]       Discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>110703</td>\n",
       "      <td>14124</td>\n",
       "      <td>2120-10-19 00:00:00</td>\n",
       "      <td>460-519 800-999</td>\n",
       "      <td>Admission Date:  [**2120-10-15**]       Discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>172000</td>\n",
       "      <td>51027</td>\n",
       "      <td>2165-01-26 00:00:00</td>\n",
       "      <td>240-279 390-459 290-319 520-579 780-789 320-38...</td>\n",
       "      <td>Admission Date:  [**2165-1-10**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>125657</td>\n",
       "      <td>81038</td>\n",
       "      <td>2144-03-20 00:00:00</td>\n",
       "      <td>001-139 390-459 290-319 520-579 780-789 580-629</td>\n",
       "      <td>Admission Date:  [**2144-3-10**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>198664</td>\n",
       "      <td>18288</td>\n",
       "      <td>2113-01-17 00:00:00</td>\n",
       "      <td>240-279 390-459 140-239 460-519 520-579</td>\n",
       "      <td>Admission Date:  [**2113-1-10**]              ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HADM_ID  SUBJECT_ID                 DATE  \\\n",
       "0   142565       56446  2198-03-12 00:00:00   \n",
       "1   158269       62415  2122-08-13 00:00:00   \n",
       "2   160831       66362  2106-08-02 00:00:00   \n",
       "3   142640       10254  2192-01-08 00:00:00   \n",
       "4   132744        9061  2198-10-17 00:00:00   \n",
       "5   107362       22087  2140-12-28 00:00:00   \n",
       "6   110703       14124  2120-10-19 00:00:00   \n",
       "7   172000       51027  2165-01-26 00:00:00   \n",
       "8   125657       81038  2144-03-20 00:00:00   \n",
       "9   198664       18288  2113-01-17 00:00:00   \n",
       "\n",
       "                                                ICD9  \\\n",
       "0  240-279 001-139 390-459 290-319 460-519 800-99...   \n",
       "1  240-279 390-459 290-319 460-519 520-579 800-99...   \n",
       "2            580-629 240-279 390-459 290-319 520-579   \n",
       "3  240-279 001-139 290-319 390-459 680-709 460-51...   \n",
       "4  240-279 760-779 001-139 390-459 460-519 520-57...   \n",
       "5                    580-629 240-279 390-459 320-389   \n",
       "6                                    460-519 800-999   \n",
       "7  240-279 390-459 290-319 520-579 780-789 320-38...   \n",
       "8    001-139 390-459 290-319 520-579 780-789 580-629   \n",
       "9            240-279 390-459 140-239 460-519 520-579   \n",
       "\n",
       "                                                TEXT  \n",
       "0  Admission Date:  [**2198-2-28**]              ...  \n",
       "1  Admission Date:  [**2122-8-1**]              D...  \n",
       "2  Admission Date:  [**2106-7-28**]              ...  \n",
       "3  Admission Date:  [**2191-12-12**]             ...  \n",
       "4  Admission Date:  [**2198-8-21**]              ...  \n",
       "5  Admission Date:  [**2140-12-19**]       Discha...  \n",
       "6  Admission Date:  [**2120-10-15**]       Discha...  \n",
       "7  Admission Date:  [**2165-1-10**]              ...  \n",
       "8  Admission Date:  [**2144-3-10**]              ...  \n",
       "9  Admission Date:  [**2113-1-10**]              ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ICD9_FIRST_LEVEL = [\n",
    "    '001-139','140-239','240-279','290-319', '320-389', '390-459','460-519', '520-579', '580-629', \n",
    "    '630-679', '680-709','710-739', '760-779', '780-789', '790-796', '797', '798', '799', '800-999' ]\n",
    "N_TOP = len(ICD9_FIRST_LEVEL)\n",
    "# replacing leave ICD9 codes with the grandparents\n",
    "df['ICD9'] = df['ICD9'].apply(lambda x: helpers.replace_with_grandparent_codes(x,ICD9_FIRST_LEVEL))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preprocess icd9 codes\n",
    "top_codes = ICD9_FIRST_LEVEL\n",
    "labels = vectorization.vectorize_icd_column(df, 'ICD9', top_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Notes\n",
    "\n",
    "The notes preprocessin here is a little different sice we want to keep dots and other characters to be able to split the notes into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for dataset\n",
    "    Every dataset is lower cased except\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"\\\\\", \"\", string)    \n",
    "    string = re.sub(r\"\\'\", \"\", string)    \n",
    "    string = re.sub(r\"\\\"\", \"\", string)    \n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "note_sentences = []\n",
    "notes = []\n",
    "\n",
    "for idx in range(df.shape[0]):\n",
    "    # for every note\n",
    "    text = clean_str(df[\"TEXT\"][idx].encode('ascii','ignore'))\n",
    "    notes.append(text)\n",
    "    sentences = tokenize.sent_tokenize(text)\n",
    "    note_sentences.append(sentences)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admission date: [**2152-6-7**]        discharge date: [**2152-6-12**] date of birth:  [**2101-7-10**]        sex:  f service:  vsu chief complaint:  calf claudication bilaterally, left greater than right.',\n",
       " 'left heel rest pain.',\n",
       " 'history of present illness:  this 50 year-old female with known peripheral vascular disease who underwent a left femoral artery angioplasty and stenting 4 years ago at [**hospital3 9717**], presents with progressive claudication of the calves bilaterally, left greater than right.',\n",
       " 'left heel rest pain over the last 4 years.',\n",
       " 'the patients  rest pain is relieved with dangling her foot.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "note_sentences[0][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what will be the MAX_SENTS and MAX_SENT_LENGTH ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of sentences in a note:  103.609108159\n",
      "Max number of sentences in a note:  547\n"
     ]
    }
   ],
   "source": [
    "note_sentences_length =[len(x) for x in note_sentences]\n",
    "print \"Average number of sentences in a note: \", np.mean(note_sentences_length)  \n",
    "print \"Max number of sentences in a note: \", max(note_sentences_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.array(note_sentences_length) > 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of words in a sentence:  16.9046097213\n",
      "Max number of words in a sentence:  3600\n"
     ]
    }
   ],
   "source": [
    "sentence_flat_list = [sentence for note_sentence in note_sentences for sentence in note_sentence]\n",
    "sentence_words_length =[len(text_to_word_sequence(sentence)) for sentence in sentence_flat_list]\n",
    "print \"Average number of words in a sentence: \", np.mean(sentence_words_length)  \n",
    "print \"Max number of words in a sentence: \", max(sentence_words_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1576"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.array(sentence_words_length) > 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amitabha/anaconda/lib/python2.7/site-packages/keras/preprocessing/text.py:139: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    }
   ],
   "source": [
    "MAX_NB_WORDS = None\n",
    "MAX_SENTS = 300\n",
    "MAX_SENT_LENGTH  = 250\n",
    "\n",
    "MAX_VOCAB = None # to limit original number of words (None if no limit)\n",
    "tokenizer = Tokenizer(nb_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(notes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = len(tokenizer.word_index)  #vocabulary length\n",
    "note_matrix = np.zeros((len(notes), MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\n",
    "\n",
    "for i, one_note_sentences in enumerate(note_sentences):\n",
    "    for j, sentence in enumerate(one_note_sentences):\n",
    "        if j< MAX_SENTS:\n",
    "            wordTokens = text_to_word_sequence(sentence)\n",
    "            k=0\n",
    "            for _, word in enumerate(wordTokens):\n",
    "                if k<MAX_SENT_LENGTH and tokenizer.word_index[word]<MAX_NB_WORDS:\n",
    "                    note_matrix[i,j,k] = tokenizer.word_index[word]\n",
    "                    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   55,    56,  1053,     9,   167,    30,    56,  1053,    13,\n",
       "          41,    56,     3,   246,  1832,    13,   167,   274,   155,\n",
       "         116,   416,   174,   538,  1112,   328,    65,   295,   250,\n",
       "          69,   350,   331,   778,  1347,   570,   345,   195,    31,\n",
       "         339,   198,   877,  1547, 12837,    49,   849,  1876,   784,\n",
       "         520,   423,    49,    79,   217,   423,    44,     3,   150,\n",
       "         259,   401,   104,   226, 26647,    18,     8,  1380,   901,\n",
       "         155,     7,  1640,   476,   941,  2165,     7,   778,     2,\n",
       "         265,    58,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "note_matrix[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train: ', (3688, 300, 250), (3688, 19))\n",
      "('Validation: ', (1054, 300, 250), (1054, 19))\n",
      "('Test: ', (528, 300, 250), (528, 19))\n"
     ]
    }
   ],
   "source": [
    "#split sets\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = helpers.train_val_test_split(\n",
    "    note_matrix, labels, val_size=0.2, test_size=0.1, random_state=101)\n",
    "print(\"Train: \", X_train.shape, y_train.shape)\n",
    "print(\"Validation: \", X_val.shape, y_val.shape)\n",
    "print(\"Test: \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "# cut texts after this number of words\n",
    "# (among top max_features most common words)\n",
    "maxlen = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "('x_train shape:', (3688, 100, 250))\n",
      "('x_test shape:', (528, 100, 250))\n",
      "('X_val shape:', (1054, 100, 250))\n"
     ]
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "X_val  = sequence.pad_sequences(X_val, maxlen=maxlen)\n",
    "print('x_train shape:', X_train.shape)\n",
    "print('x_test shape:', X_test.shape)\n",
    "print('X_val shape:', X_val.shape)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Vocabulary in notes:', 66150)\n",
      "('Vocabulary in original embedding:', 400000)\n",
      "('Vocabulary intersection:', 25236)\n"
     ]
    }
   ],
   "source": [
    "#creating embeddings\n",
    "EMBEDDING_LOC = '../data/glove.6B.100d.txt' # location of embedding\n",
    "EMBEDDING_DIM = 100 # given the glove that we chose\n",
    "EMBEDDING_MATRIX, embedding_dict = vectorization.embedding_matrix(EMBEDDING_LOC,\n",
    "                                                                  dictionary, EMBEDDING_DIM, verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitting - Bidirectional LSTM\n",
      "('X_train.shape ', (3688, 100, 250))\n",
      "('y_train.shape ', (3688, 19))\n",
      "('X_test.shape ', (528, 100, 250))\n",
      "('y_test.shape ', (528, 19))\n",
      "('X_val.shape ', (1054, 100, 250))\n",
      "('y_val.shape ', (1054, 19))\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_16 (Embedding)     (None, 1000, 100)         6615100   \n",
      "_________________________________________________________________\n",
      "bidirectional_16 (Bidirectio (None, 200)               160800    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 6,776,302\n",
      "Trainable params: 6,776,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_14 to have 2 dimensions, but got array with shape (3688, 100, 250)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-97c52408f27f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/amitabha/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1358\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1359\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amitabha/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1232\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1234\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1235\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1236\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/amitabha/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_14 to have 2 dimensions, but got array with shape (3688, 100, 250)"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[EMBEDDING_MATRIX],\n",
    "                            #input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True)\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "l_lstm = Bidirectional(LSTM(100))(embedded_sequences)\n",
    "preds = Dense(2, activation='softmax')(l_lstm)\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "print(\"model fitting - Bidirectional LSTM\")\n",
    "print(\"X_train.shape \", X_train.shape)\n",
    "print(\"y_train.shape \", y_train.shape)\n",
    "\n",
    "print(\"X_test.shape \", X_test.shape)\n",
    "print(\"y_test.shape \", y_test.shape)\n",
    "\n",
    "print(\"X_val.shape \", X_val.shape)\n",
    "print(\"y_val.shape \", y_val.shape)\n",
    "\n",
    "print(X_train.t)\n",
    "\n",
    "model.summary()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
