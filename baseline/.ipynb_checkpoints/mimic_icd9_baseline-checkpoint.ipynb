{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import *\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import nn_model\n",
    "from sklearn.metrics import label_ranking_loss\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File built from MIMIC III database\n",
    "\n",
    "The dis_notes_icd9.csv file was created from the MIMIC III database by filtering and joining a couple of tables. For details on the pre-processing phase: https://github.com/letslego/W266-ProjectMIMIC/tree/master/baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('psql_files/dis_notes_icd9.csv', 'rb') as csvfile:\n",
    "    discharge_notes_reader = csv.reader(csvfile)\n",
    "    discharge_notes_list = list(discharge_notes_reader)    \n",
    "random.shuffle(discharge_notes_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample of a discharge summary and the ICD( codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of a discharge note:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Admission id:  180733\n",
      "Subject id: 32517\n",
      "Discharge date: 2196-11-02 00:00:00\n",
      "ICD9 codes assigned to this discharge summary:  4019 25000 496 4280\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Discharge Summary Clinical Note: \n",
      "----------------------------------------------------------------------------------------------------\n",
      "MIMIC data is visible to only authorized users\n"
     ]
    }
   ],
   "source": [
    "print 'Sample of a discharge note:'\n",
    "print \"-\" *100\n",
    "admission_id, subject_id, discharge_date, note_text, icd9_codes = discharge_notes_list[1]\n",
    "print \"Admission id: \", admission_id\n",
    "print \"Subject id:\", subject_id\n",
    "print \"Discharge date:\", discharge_date\n",
    "print \"ICD9 codes assigned to this discharge summary: \", icd9_codes\n",
    "print \"-\" *100\n",
    "print \"Discharge Summary Clinical Note: \"\n",
    "print \"-\" *100\n",
    "#print note_text \n",
    "print \"MIMIC data is visible to only authorized users\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Baseline\n",
    "\n",
    "This is a multilabel classification since each discharge summary has several icd9 codes assigned. The most simple baseline will be to predict the top N icd9 codes for each discharge summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting files in training, dev and test\n",
    "\n",
    "(note: moving discharge_notes_list into an np array needs about 8 GB of ram (even though the file is about 450MB) then here we work just with lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_file(data, train_frac = 0.7, dev_frac = 0.15):   \n",
    "    train_split_idx = int(train_frac * len(data))\n",
    "    dev_split_idx = int ((train_frac + dev_frac)* len(data))\n",
    "    train_data = data[:train_split_idx]\n",
    "    dev_data = data[train_split_idx:dev_split_idx]\n",
    "    test_data = data[dev_split_idx:]\n",
    "    return train_data, dev_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set samples: 32085\n",
      "Dev set samples: 6876\n",
      "Test set samples: 6876\n"
     ]
    }
   ],
   "source": [
    "notes= [row[3] for row in discharge_notes_list]\n",
    "labels = [row[4] for row in discharge_notes_list]\n",
    "train_data_notes, dev_data_notes, test_data_notes = split_file (notes)\n",
    "train_data_labels, dev_data_labels, test_data_labels = split_file (labels)\n",
    "print 'Training set samples:', len (train_data_notes)\n",
    "print 'Dev set samples:', len (dev_data_notes)\n",
    "print 'Test set samples:', len (test_data_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding out list of unique icd9 codes and the top 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most common 4 icd9_codes:  [('4019', 20721), ('4280', 13507), ('42731', 13150), ('41401', 12672)]\n",
      "label for the top 4 icd9 codes:  4019 4280 42731 41401\n"
     ]
    }
   ],
   "source": [
    "# finding out the top icd9 codes\n",
    "icd9_codes = Counter()\n",
    "for label in labels:\n",
    "    for icd9_code in label.split():\n",
    "        icd9_codes[icd9_code] += 1\n",
    "top_4_icd9 = icd9_codes.most_common(4)\n",
    "print \"most common 4 icd9_codes: \", top_4_icd9\n",
    "\n",
    "top_4_icd9_label = ' '.join(code for code,count in top_4_icd9 )\n",
    "print 'label for the top 4 icd9 codes: ', top_4_icd9_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of unique icd9 codes from all labels:  ['2859', '4019', '2724', '25000', '99592', '2851', '2762', '2449', '4280', '0389', '41401', '53081', '5849', '2720', '42731', '486', '496', '5070', '51881', '5990']\n"
     ]
    }
   ],
   "source": [
    "# list of unique icd9_codes and lookups for its index in the vector\n",
    "unique_icd9_codes = list (icd9_codes)\n",
    "index_to_icd9 = dict(enumerate(unique_icd9_codes))\n",
    "icd9_to_id = {v:k for k,v in index_to_icd9.iteritems()}\n",
    "print 'List of unique icd9 codes from all labels: ', unique_icd9_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting icd9 labels to vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each discharge note label is a list of icd9 codes, for example: \n",
    "```\n",
    "4019 25000 496 4280   \n",
    "```\n",
    "we will represent it as a vector for the multilabel classification process, the vector would look like:\n",
    "```\n",
    "[0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#transforming list of icd_codes into a vector\n",
    "def get_icd9_array(icd9_codes):\n",
    "    icd9_index_array = [0]*len(unique_icd9_codes)\n",
    "    for icd9_code in icd9_codes.split():\n",
    "        icd9_index_array[icd9_to_id [icd9_code]] = 1\n",
    "    return icd9_index_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "icd9 prediction vector:  [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "#top 4 common icd9 to vector\n",
    "icd9_prediction_vector = get_icd9_array(top_4_icd9_label)\n",
    "print 'icd9 prediction vector: ', icd9_prediction_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example of a training label vector:  [0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# true icd9 codes to vector\n",
    "train_data_labels_vector= list(map(get_icd9_array, train_data_labels))\n",
    "dev_data_labels_vector = list(map(get_icd9_array, dev_data_labels))\n",
    "print 'example of a training label vector: ', train_data_labels_vector[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## assign icd9_prediction_vector to every discharge\n",
    "train_y_hat_baseline = [icd9_prediction_vector]* len (train_data_labels_vector)\n",
    "dev_y_hat_baseline = [icd9_prediction_vector]* len (dev_data_labels_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ranking loss:  0.651733663207\n",
      "Development ranking loss:  0.65130016997\n"
     ]
    }
   ],
   "source": [
    "training_ranking_loss = label_ranking_loss(train_data_labels_vector, train_y_hat_baseline)\n",
    "print \"Training ranking loss: \", training_ranking_loss\n",
    "dev_ranking_loss = label_ranking_loss(dev_data_labels_vector, dev_y_hat_baseline)\n",
    "print \"Development ranking loss: \", dev_ranking_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  NN Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: \n",
    "the input file is about 450 MB, with 45,837 discharge summaries. The google instance needed 3 CPUs (~ 8 GB memory ) to hold it in an np array. We need np arrays for tensorflow. Here I will be working with the first 5,000 records for the NN Baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of discharge clinical notes:  5000\n"
     ]
    }
   ],
   "source": [
    "# the full file needs about 8GB of memory, let's work with the first 5000\n",
    "#discharge_notes= np.asarray(discharge_notes_list)\n",
    "discharge_notes= np.asarray(discharge_notes_list[0:5000])\n",
    "print 'Number of discharge clinical notes: ', len(discharge_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discharge_notes= [row[3] for row in discharge_notes]\n",
    "discharge_labels = [row[4] for row in discharge_notes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set samples: 3500\n",
      "Dev set samples: 750\n",
      "Test set samples: 750\n"
     ]
    }
   ],
   "source": [
    "train_notes, dev_notes, test_notes = split_file (discharge_notes)\n",
    "train_labels, dev_labels, test_labels = split_file (discharge_labels)\n",
    "print 'Training set samples:', len (train_notes)\n",
    "print 'Dev set samples:', len (dev_notes)\n",
    "print 'Test set samples:', len (test_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  TF-IDF Representation of discharge clinical notes\n",
    "\n",
    "Previous research represents this documents/notes as bag-of-words vectors [1].    \n",
    "In particular, it takes the 10,000 tokens with the largest tf-idf scores from the training.\n",
    " \n",
    "[1] Diagnosis code assignment: models and evaluation metrics. Journal of the American Medical Informatics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_number_features = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TfidfVectorizer\n",
    "# Convert all characters to lowercase before tokenizing (by default)\n",
    "# tokenization (by default)\n",
    "# max_features: consider the top max_features ordered by term frequency across the corpus\n",
    "vectorizer = TfidfVectorizer(max_features=max_number_features,stop_words='english',max_df=0.9 )  \n",
    "train_notes_vector = vectorizer.fit_transform(train_notes)\n",
    "dev_notes_vector = vectorizer.transform(dev_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming list of ICD codes to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels_vector= list(map(get_icd9_array, train_labels))\n",
    "dev_labels_vector = list(map(get_icd9_array, dev_labels))\n",
    "test_labels_vector = list(map(get_icd9_array, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network for Multilabel classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_epoch(lm, session, X, y, batch_size):\n",
    "    for batch in xrange(0, X.shape[0], batch_size):\n",
    "        X_batch = X[batch : batch + batch_size]\n",
    "        y_batch = y[batch : batch + batch_size]\n",
    "        feed_dict = {lm.x:X_batch,lm.target_y:y_batch}\n",
    "        loss, train_op_value =  session.run( [lm.loss,lm.train],feed_dict=feed_dict ) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_icd9_codes(lm, session, x_data, y_dim):\n",
    "    total_y_hat = []\n",
    "    for batch in xrange(0, x_data.shape[0], batch_size):\n",
    "        X_batch = x_data[batch : batch + batch_size]\n",
    "        y_hat_out = session.run(lm.y_hat, feed_dict={lm.x:X_batch})\n",
    "        total_y_hat.extend(y_hat_out)\n",
    "    return  total_y_hat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#build tensorflow graphs\n",
    "reload(nn_model)\n",
    "\n",
    "# Model parameters\n",
    "Hidden_dims = [100]\n",
    "learning_rate = 0.01\n",
    "y_dim = len(unique_icd9_codes)\n",
    "model_params = dict(Hidden_dims=Hidden_dims, \n",
    "                    learning_rate = learning_rate, vocabulary_size =max_number_features , y_dim=y_dim)\n",
    "\n",
    "lm = nn_model.NNLM(**model_params)\n",
    "lm.BuildCoreGraph()\n",
    "lm.BuildTrainGraph()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = train_notes_vector.todense()\n",
    "y = train_labels_vector\n",
    "batch_size = 50\n",
    "num_epochs = 50\n",
    "\n",
    "with lm.graph.as_default():\n",
    "    initializer = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session(graph=lm.graph) as session:\n",
    "    session.run(initializer)\n",
    "    #training\n",
    "    for epoch_num in xrange(num_epochs):\n",
    "        run_epoch(lm, session, X, y, batch_size)\n",
    "    #prediction using training and dev data \n",
    "    train_y_hat = predict_icd9_codes(lm, session, train_notes_vector.todense(), y_dim)\n",
    "    dev_y_hat = predict_icd9_codes(lm, session, dev_notes_vector.todense(), y_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ranking loss:  0.328117881062\n",
      "Development ranking loss:  0.324885189983\n"
     ]
    }
   ],
   "source": [
    "training_ranking_loss = label_ranking_loss(train_labels_vector, train_y_hat)\n",
    "print \"Training ranking loss: \", training_ranking_loss\n",
    "dev_ranking_loss = label_ranking_loss(dev_labels_vector, dev_y_hat)\n",
    "print \"Development ranking loss: \", dev_ranking_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The following paper \"ICD-9 Coding of Discharge Summaries\"  worked with the MIMIC II database to classify ICD9-codes, \n",
    "the ranking loss metrics reported are:\n",
    "<img src=\"paper_ranking_loss_scores.png\">\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
